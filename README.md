# image_captioning
* Uses a dataset of images with each image containing 5 descriptions
* The Inception V3 model is used with pre-trained weights
* Given an image the model predicts a sequence of words to form a sentence that describes the image

  
